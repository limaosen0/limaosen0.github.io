---
layout:     post
title:      Unsupervised Local Facial Attributes Transfer Using Dual Discriminative Adversarial Networks
subtitle:   Accepted as Poster at ICME 2018
date:       2019-04-19
author:     Maosen
header-img: img/post-bg-glasses.jpg
catalog: true
tags:
    - ICME
    - Face
    - Image Synthesis
    - Style Transfer
    - Adversarial
---
>Authors: Yu Li, Maosen Li, Ya Zhang and Ying Wang. 

Facial attributes transfer is a challenging problem in computer vision and image processing. We propose a new structure for local facial attributes transfer, called Dual Discriminative Adversarial Networks (DDAN). Given a source image with a certain local attribute, the DDAN model transforms source images with a certain attribute to target images without the same attribute while keeping the other attributes unchanged. A two-branch discriminator is introduced in the proposed DDAN model to simultaneously represent local and global features. 

# Introduction
- What is local facial attributes? Local facial attributes indicate that some specific attributes appear at local regions of the faces. For example, wearing glasses, mouth open and mustaches. In contrary, global facial attributes denote features on the whole faces which represent more abstract information of people, such as genders and ages. 
- The challenging of local factial attributes transferring. Some local attributes (e.g. shapes of eyes and noses) are essential in defining personal identity, but many may have varieties of values for the same person, such as wearing accessories or mouse poses. We deal with the later ones. The transfer task aims to modify certain attributes of a facial image but keep the identity unchanged. Most proposed models could not explicitly transfer the local attributes. Nonetheless, unpaired data is usually available compared with paired data and more difficult to utilize. We attempt to employ the unpaired data to implement the attributes transferring.
- Example of global/local facial attributes transferring.
![](https://github.com/limaosen0/limaosen0.github.io/blob/master/img_post/icme_2018_fig1.jpg =100)

# Dual Discriminative Adversarial Networks

# Experiments and Results

# Conclusion
DDAN model performs well in attributes transfer task and the two-branch discriminator plays an important role in the entire model. Local attributes information can be utilized sufficiently to alter the local part. To train the generative networks, we design four parts loss to force the generator gradient to update in right direction. Identity loss can keep the people identity the same, global adversarial loss aims to eliminate the attribute edge and make generated images more real, attribute adversarial loss can capture local attributes feature for better image texture and total variation regularization smooth the final images. Our work is conducted on unpaired data, which is usually available compared with paired data and more difficult to utilize, and we will extend our work to global attributes transfer in future work.
